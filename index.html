<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Designing for AI Transparency & Trust — Case Study</title>
  <meta name="description" content="Case study site documenting UX/UI process for Quebec Government AI transparency project." />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Manrope:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="index.css" />
</head>
<body>
  <a class="skip-link" href="#main">Skip to main content</a>

  <header class="site-header" role="banner">
    <div class="container header-main">
      <a class="brand" href="#overview">
        <img class="brand-icon" src="images/medisignal-logo.png" alt="Medisignal logo">
        <span class="brand-text">
          <span class="brand-name">QC•AI Studio</span>
          <span class="brand-tagline">Designing trustworthy public services</span>
        </span>
      </a>
      <nav class="site-nav" id="primary-nav" aria-label="Primary navigation">
        <ul>
          <li><a href="#overview">Overview</a></li>
          <li><a href="#research">Research</a></li>
          <li><a href="#personas">Personas</a></li>
          <li><a href="#journeys">Journey</a></li>
          <li><a href="#wireframes">Sketches</a></li>
          <li><a href="#design">Design </a></li>
          <li><a href="#ethics">Ethics</a></li>
          <li><a href="#evidence">Evidence</a></li>
          <li><a href="#references">Deliverables</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <main id="main">
    <section class="hero" id="overview">
      <div class="container hero-inner">
        <div class="hero-text">
          <h1>Bridging Quebec's Healthcare Gap with Trustworthy AI</h1>
          <p class="lead">Quebec's medical system is in crisis. With 2.1 million residents lacking access to a family doctor and emergency rooms overflowing, we were commissioned to design an AI-powered health platform that earns public trust and delivers reliable care to those who need it most.</p>
          <div class="hero-actions">
            <a class="btn primary" href="#problem">Explore the challenge</a>
            <a class="btn ghost" href="#research">View our research</a>
            <a class="btn secondary" href="#design">See the solution</a>
          </div>
        </div>
        <div class="hero-visual" aria-hidden="true">
          <img src="https://images.unsplash.com/photo-1576091160399-112ba8d25d1d?auto=format&fit=crop&w=1200&q=80" alt="Medical professional with digital interface">
          <div class="caption">
            <strong>Our Mission</strong>
            <span>Design an AI health assistant that 2.1 million Quebecers without family doctors can trust with their care.</span>
          </div>
        </div>
      </div>
    </section>

    <section class="section alt" id="problem">
      <div class="container">
        <div class="section-header">
          <h2>The Healthcare Crisis</h2>
          <p class="section-intro">Quebec's healthcare system is collapsing under the weight of unprecedented demand. Months-long waits for family doctors, overcrowded emergency rooms, and severely limited access to basic medical resources have created a public health emergency that demands innovative solutions.</p>
        </div>
        <div class="timeline" id="timeline">
          <div class="timeline-item">
            <h3>The Scale of the Problem</h3>
            <p>According to the 2024 INESS report, <strong>2.1 million Quebec residents lack access to a family doctor</strong>. Emergency rooms have become the default primary care provider, creating dangerous bottlenecks and exhausting healthcare workers. Basic preventive care and chronic disease management are increasingly out of reach for vulnerable populations.</p>
          </div>
          <div class="timeline-item">
            <h3>The Trust Barrier</h3>
            <p>While AI technology offers tremendous potential to improve healthcare access, we face a fundamental barrier: <strong>public trust</strong>. Many Quebec residents, particularly those without technical backgrounds, harbor deep skepticism about artificial intelligence in healthcare.</p>
            <ul class="highlight-list">
              <li>Can AI provide accurate medical guidance compared to human doctors?</li>
              <li>Should patients follow AI recommendations for their health decisions?</li>
              <li>Who bears responsibility if the AI provides incorrect guidance?</li>
            </ul>
          </div>
          <div class="timeline-item">
            <h3>Our Design Challenge</h3>
            <p>This lack of trust threatens to undermine a solution designed to help Quebec's healthcare crisis. Without user confidence and adoption, even the most sophisticated AI system will fail to serve those who need it most. <strong>Our responsibility is to build a trustworthy AI service that Quebec residents can confidently rely on.</strong></p>
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="research">
      <div class="container">
        <div class="section-header">
          <h2>Understanding Our Users</h2>
          <p class="section-intro">To build a trustworthy AI health platform, we first needed to understand the people we're designing for. Our research focused on uncovering the requirements, fears, and expectations that would determine whether Quebec residents would trust AI with their healthcare decisions.</p>
        </div>
        <div class="cards-grid">
          <article class="card">
            <h3>Research Approach</h3>
            <p>We conducted a comprehensive survey examining the relationship between humans and AI-driven medical services. This questionnaire helped us identify the key requirements our service must meet to earn the trust of Quebec citizens.</p>
            <ul class="highlight-list">
              <li>Targeted diverse backgrounds and age groups</li>
              <li>Included respondents with and without technological expertise</li>
              <li>Captured perspectives from both urban and rural communities</li>
            </ul>
          </article>
          <article class="card">
            <h3>Key Research Questions</h3>
            <p>Our survey explored critical trust factors that would determine platform adoption and user confidence in AI-generated health guidance.</p>
            <ul class="highlight-list">
              <li>What makes users trust (or distrust) AI health recommendations?</li>
              <li>How much transparency do users need to feel confident?</li>
              <li>When do users prefer human intervention over AI guidance?</li>
            </ul>
          </article>
          <article class="card">
            <h3>Research Insights</h3>
            <p>Our findings revealed specific design principles that would build trust across diverse user groups, from tech-savvy millennials to elderly residents unfamiliar with AI.</p>
            <ul class="highlight-list">
              <li>Users demand clear explanations of how AI reaches conclusions</li>
              <li>Transparency about AI limitations builds more trust than overpromising</li>
              <li>Easy access to human healthcare providers is non-negotiable</li>
            </ul>
          </article>
        </div>
        
        <div style="margin-top: 64px; max-width: 1600px; margin-left: auto; margin-right: auto;">
          <div class="section-header">
            <h3>Survey Results</h3>
            <p class="section-intro">Key findings from our comprehensive survey of Quebec residents regarding AI healthcare trust and adoption.</p>
          </div>
          
          <div style="display: grid; grid-template-columns: 1fr; gap: 48px; margin-top: 32px;">
            <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
              <img src="images/research_result_1.png" alt="Survey result 1 - Trust factors in AI healthcare" style="width: 100%; height: auto; display: block; border-radius: 0;">
              <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">Trust factors that influence AI healthcare adoption among Quebec residents</figcaption>
            </figure>
            <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
              <img src="images/research_result_2.png" alt="Survey result 2 - User concerns and barriers" style="width: 100%; height: auto; display: block; border-radius: 0;">
              <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">Primary concerns and barriers preventing users from trusting AI medical guidance</figcaption>
            </figure>
            <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
              <img src="images/research_result_3.png" alt="Survey result 3 - Transparency preferences" style="width: 100%; height: auto; display: block; border-radius: 0;">
              <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">User preferences for AI transparency and explainability features</figcaption>
            </figure>
            <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
              <img src="images/research_result_4.png" alt="Survey result 4 - Human intervention expectations" style="width: 100%; height: auto; display: block; border-radius: 0;">
              <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">When and how users expect human healthcare providers to intervene</figcaption>
            </figure>
          </div>
          
          <div style="margin-top: 48px; padding: 32px; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12);">
            <h4 style="margin-top: 0; margin-bottom: 24px; color: var(--primary);">Key Findings</h4>
            <p style="line-height: 1.6; margin-bottom: 16px;">The primary concern preventing AI adoption for health questions is inaccurate or misleading information (38.9%), followed closely by privacy and data security risks (25%). Notably, only a small minority feel comfortable using AI for health-related questions without reservations.</p>
            
            <p style="line-height: 1.6; margin-bottom: 16px;">When it comes to building trust, nearly half of respondents (44.4%) want AI services to provide sources or links to credible information. Transparency in reasoning is also valued, with 22.2% wanting to understand the AI's thought process. Interestingly, professional endorsement matters significantly since 69.4% of our users consider it very important for a healthcare worker to review the AI's recommendations, and two-thirds want maximum detail about the sources and information the AI used.</p>
            
            <p style="line-height: 1.6; margin-bottom: 16px;">The overwhelming majority (91.7%) would find it helpful if the AI showed its step-by-step thinking process, reinforcing the critical need for explainability in medical AI applications.</p>
            
            <p style="line-height: 1.6; margin-bottom: 0;"><strong>Therefore, the key takeways are that users want AI health services that prioritize accuracy, cite credible sources, show their reasoning transparently, and operate with human oversight. Trust isn't just about the technology, it's also about accountability and clarity.</strong></p>
          </div>
        </div>
      </div>
    </section>

    <section class="section alt" id="personas">
      <div class="container">
        <div class="section-header">
          <h2>User personas & requirements</h2>
          <p class="section-intro">Our research revealed three distinct user archetypes that represent the diverse needs and concerns of Quebec residents interacting with AI healthcare services.</p>
        </div>
        <div style="display: grid; grid-template-columns: 1fr; gap: 48px; margin-top: 32px; max-width: 1400px; margin-left: auto; margin-right: auto;">
          <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
            <img src="images/user_persona_1.png" alt="User Persona 1 - Primary user archetype" style="width: 100%; height: auto; display: block; border-radius: 0;">
            <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">Primary user persona representing the core target audience for the AI health platform</figcaption>
          </figure>
          
          <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
            <img src="images/user_persona_2.png" alt="User Persona 2 - Secondary user archetype" style="width: 100%; height: auto; display: block; border-radius: 0;">
            <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">Secondary user persona highlighting additional user needs and accessibility considerations</figcaption>
          </figure>
          
          <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
            <img src="images/user_persona_3.png" alt="User Persona 3 - Edge case user archetype" style="width: 100%; height: auto; display: block; border-radius: 0;">
            <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">Edge case persona representing users with unique challenges and critical design requirements</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <section class="section" id="journeys">
      <div class="container">
        <div class="section-header">
          <h2>User journeys & task flows</h2>
          <p class="section-intro">Mapping how users interact with the AI health assistant from initial intent through to resolution, highlighting critical touchpoints for transparency, human support, and safety measures.</p>
        </div>
        <div style="display: grid; grid-template-columns: 1fr; gap: 48px; margin-top: 32px; max-width: 1600px; margin-left: auto; margin-right: auto;">
          <figure style="margin: 0; background: var(--surface); border-radius: var(--radius); border: 1px solid rgba(10,75,120,0.12); overflow: hidden; box-shadow: var(--shadow-soft);">
            <img src="images/journey_map.png" alt="User journey map showing the complete interaction flow with the AI health platform" style="width: 100%; height: auto; display: block; border-radius: 0;">
            <figcaption style="padding: 20px; color: var(--muted); font-size: 1rem;">Complete user journey map illustrating key stages, pain points, and opportunities for building trust throughout the AI healthcare experience</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <section class="section alt" id="wireframes">
      <div class="container">
        <div class="section-header">
          <h2>Sketches & wireframes</h2>
          <p class="section-intro">Trace the design evolution—from a marker sketch mapping transparency touchpoints, through a clarified user-flow diagram, to mid-fidelity wireframes that translate trust requirements into screens the team can build.</p>
        </div>
        <div class="gallery">
          <figure class="gallery-item gallery-sketch">
            <img src="images/ProjectSketches.jpg" alt="Early project sketches for transparency controls">
            <figcaption>Early sketch explorations of transparency controls and confidence explanations.</figcaption>
          </figure>
          <figure class="gallery-item gallery-flow">
            <img src="images/UserFlowDiagram.jpeg" alt="User flow diagram showing key decision points">
            <figcaption>Iteration comparisons showing improvements to language clarity and escalation paths.</figcaption>
          </figure>
          <figure class="gallery-item gallery-wireframe">
            <img src="images/Wireframe.jpg" alt="Mid-fidelity wireframes for onboarding and AI output screens">
            <figcaption>Mid-fidelity wireframes illustrating onboarding and AI output screen flow.</figcaption>
          </figure>
        </div>

      </div>
    </section>

    <section class="section" id="design">
      <div class="container">
        <div class="section-header">
          <h2>Design system & final mockups</h2>
          <p class="section-intro">
            Surface the final Medisignal experience—calming blue gradients, 3D care avatars, and the trust signals that guide patients from login to AI-assisted triage.
          </p>
        </div>

        <div class="design-grid">
          <article class="design-panel">
            <h3>Visual language</h3>
            <ul class="design-points">
              <li><strong>Palette:</strong> Misty hospital blues with neon health green CTAs and emergency coral alerts.</li>
              <li><strong>Typography:</strong> Rounded sans serif (Manrope/Inter) for accessible copy and crisp data labels.</li>
              <li><strong>Iconography:</strong> 3D caregiver avatar and soft-stroke system icons that reinforce reassurance.</li>
              <li><strong>Motion:</strong> Gentle fades and meters that reveal AI certainty without overwhelming the user.</li>
            </ul>
          </article>

          <article class="design-panel">
            <h3>Component library</h3>
            <ul class="design-points">
              <li>Severity cards that color-code low, medium, and high risk plans of action.</li>
              <li>Symptom capture modules with camera prompts and cancel/back affordances.</li>
              <li>AI reliability meter paired with educational tooltips and escalation buttons.</li>
            </ul>
          </article>

          <article class="design-panel design-panel--wide">
            <h3>Prototype highlights</h3>
            <ul class="design-points">
              <li>Interactive flow covering onboarding, dashboard doctor search, and symptom submission.</li>
              <li>Camera pathway that feeds the AI scan while preserving user control and consent.</li>
              <li>Severity outcomes that map to OTC advice, doctor referrals, or urgent care escalation.</li>
            </ul>
          </article>
        </div>

        <div class="mockup-embed" aria-label="Interactive prototype of the Medisignal app">
          <iframe
            src="https://embed.figma.com/design/Zi7NPPTlWt2503HfnFrBrl/SOEN-357-Mini-Project?node-id=0-1&embed-host=share"
            allowfullscreen>
          </iframe>
        </div>
      </div>
    </section>

    <section class="section" id="evidence">
      <div class="container">
        <div class="section-header">
          <h2>Evidence of user research</h2>
          <p class="section-intro">
            Thirty Quebec residents shared what earns (and loses) their trust: 40% fear inaccurate AI advice, 66.7% demand human review, and 93.3% want to see the assistant’s reasoning. Medisignal’s final features answer those signals directly.
          </p>
        </div>

        <div class="impact-gallery">
          <figure class="impact-card">
            <img src="images/evidence_reviewer.png" alt="Reviewer confirmation screen with cited medical sources">
            <figcaption>
              66.7% of participants rated it “very important” to know a healthcare worker reviewed recommendations. The reviewer tile and source links make the human sign‑off and evidence trail visible before acting.
            </figcaption>
          </figure>
          <figure class="impact-card">
            <img src="images/evidence_doctorlist.png" alt="Doctor selection screen with specialty filters and ratings">
            <figcaption>
              With 40% worried about inaccurate guidance and 33.3% looking for reputable professionals, we added specialty filters, credentials, and ratings so users can choose the clinician who validates the AI outcome.
            </figcaption>
          </figure>
          <figure class="impact-card">
            <img src="images/evidence_camera.png" alt="Camera triage screen with live AI assistant">
            <figcaption>
              Because 93.3% wanted the AI to explain its thinking step by step, the camera triage view streams live transcripts and escalation controls while the assistant analyses imagery.
            </figcaption>
          </figure>
        </div>

        <div class="cards-grid" style="margin-top:32px;">
          <article class="card">
            <h3>User quotes</h3>
            <p>“I trust it when a real doctor signs the result and I can open the source myself.”</p>
            <p>“Let me pick the specialist; don’t lock me into whoever the AI suggests.”</p>
          </article>
          <article class="card">
            <h3>Research appendix</h3>
            <ul class="highlight-list">
              <li>Survey charts on trust blockers (40% cite inaccurate info, 30% privacy risk).</li>
              <li>Reliability drivers: 46.7% want cited sources, 20% want pro endorsements.</li>
              <li>Explainability demand: 93.3% request a visible reasoning trail.</li>
            </ul>
          </article>
          <article class="card">
            <h3>Iteration log</h3>
            <ul class="highlight-list">
              <li>v1 → v2: Added human reviewer badge after 66.7% asked for clinician oversight.</li>
              <li>v2 → v3: Introduced source chips and specialty filters to counter accuracy fears.</li>
              <li>v3 → Final: Embedded live transcript during camera triage to satisfy the 93.3% explainability request.</li>
            </ul>
          </article>
        </div>
      </div>
    </section>



    <section class="section alt" id="references">
      <div class="container">
        <div class="section-header">
          <h2>References & deliverables</h2>
          <p class="section-intro">Gather everything the Quebec Government reviewers need in one place.</p>
        </div>
        <div class="cards-grid">
          <article class="card">
            <h3>Deliverables checklist</h3>
            <ul class="highlight-list">
              <li>Live case study URL (this page)</li>
              <li>PDF export for Moodle submission</li>
              <li>Links to prototypes (Figma, XD, etc.)</li>
              <li>Appendix with ethics forms (private)</li>
            </ul>
          </article>
          <article class="card">
            <h3>Reference library</h3>
            <ul class="references">
              <li><a href="https://uxdesign.cc/10-steps-to-interaction-design-ixd-6abe778cb8b8" target="_blank" rel="noopener">Interaction design process</a></li>
              <li><a href="https://careerfoundry.com/en/blog/ux-design/wireframing-tools-ux-designers/" target="_blank" rel="noopener">Wireframing tools</a></li>
              <li><a href="https://blog.prototypr.io/a-common-product-ux-design-process-55af4ab5665e" target="_blank" rel="noopener">UX process guide</a></li>
              <li><a href="https://www.figma.com" target="_blank" rel="noopener">Figma</a></li>
              <li><a href="http://www.unumux.com/assets/Unum-User-Research-Guidelines.pdf" target="_blank" rel="noopener">User research guidelines</a></li>
            </ul>
          </article>
        </div>
      </div>
    </section>
  </main>

  <footer class="site-footer">
    <div class="container">
      <div class="footer-inner">
        <div>
          <h4>QC•AI Studio</h4>
          <p>Design team partnering with the Quebec Government to deliver transparent AI experiences.</p>
        </div>
        <div>
          <h4>Explore</h4>
          <ul>
            <li><a href="#overview">Project overview</a></li>
            <li><a href="#research">Research</a></li>
            <li><a href="#design">Design system</a></li>
            <li><a href="#references">Deliverables</a></li>
          </ul>
        </div>
        <div>
          <h4>Contact</h4>
          <ul>
            <li><!-- Team email --></li>
            <li><!-- Contact person & role --></li>
            <li><!-- Office hours / availability --></li>
          </ul>
        </div>
      </div>
      <div class="footer-bottom">
        <span>© 2025 QC•AI Studio — SOEN 357 Mini Project</span>
        <span><a href="#overview">Back to top</a></span>
      </div>
    </div>
  </footer>
</body>
</html>